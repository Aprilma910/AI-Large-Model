Q：embedding 文件格式重要吗，用txt 和 markdown有区别吗？
如果是PDF, PPT，需要转化成 markdown形式，因为相比于txt，内容loss更小

Q：公司准备做运维场景的智能体，用什么框架开发比较好
langchain, langgraph, qwen-agent
思考运维智能体，他的功能有哪些，需要搭建哪些tool

Q：课件里面的代码需要能独立手敲出来吗
不需要
人关注的是 逻辑！

Q：用相关规范训练的知识库，可以挂到办公软件里，指导或提醒我们编写方案么？
AI Agent是可以的

Q：现在在 iPhone App 里嵌入本地大模型去完成一些功能会是将来的趋势吗？
趋势1：大，旗舰版
趋势2：小，嵌入式，手机端

Q：做 迪士尼RGA时，程序越复杂，调试越复杂，有时候 一个问题在调试时，会修改大面积别的程序，导致原本正常的运行变得不通畅，要反复很多次来修改

LangChain QAChain (LLM, chain_type)
Faiss, similarity_search(query, k=2)
input_data = {"input_documents": docs, "question": query}
response = chain.invoke(input=input_data)

数据库中的chunks => 召回 => 重排
RAG：1000万 => 召回（关键词）100个 => 重排（模型相对较大，计算量较多）
召回 可以是关键词，也可以是向量

推荐系统：1000万 => 召回 100个 => 排序

请返回JSON格式：
{
    "query_type": "查询类型",
    "rewritten_query": "改写后的查询",
    "confidence": "置信度(0-1)"
}

Q：置信度是向量夹角的cos值吗？
是LLM给出的分数（有一定的感性）

Q：意图识别是怎么调用的，也是提示词给大模型吗

Q：query改写最终只需要一个意图识别prompt就够了吗？
可以的

Q：如何评估在RAG使用中的问答模式，不同场景下的问题都可以映射到这几种吗？
改写，不一定所有的Query都需要改写。

query' => 用于后续的 embedding，从向量数据库中检索出 Topk个chunk

可以用开源的，比如 dify, ragflow, qwen-agent

Q：如何让LLM对Query进行改写，比如这里的 联网搜索，方便后续的搜索
input, output
input：query, current_time
output （JSON格式）

tavily mcp
RAG是个系统工程，存在很多的可能性
Query2Doc, Doc2Query
=> 建立更多的联系

LLM

        instruction = """
你是一个智能的查询优化助手Query2Doc。请将用户的查询改写成文档，方便后续使用这些文档进行知识库的检索
原始查询较短，可能无法充分表达用户意图。
通过 Query2Doc 生成一段扩展文档：

示例：
用户查询：“如何提高深度学习模型的训练效率？”
Query2Doc结果：
提高深度学习模型的训练效率可以从以下几个方面入手：
1. 使用更高效的优化算法，如 AdamW 或 LAMB。
2. 采用混合精度训练（Mixed Precision Training），减少显存占用并加速计算。
3. 使用分布式训练技术，如数据并行或模型并行。
4. 对数据进行预处理和增强，减少训练时的冗余计算。
5. 调整学习率调度策略，避免训练过程中的震荡。
"""



你是一个智能的查询优化助手Query2Doc。请将用户的查询改写成文档，方便后续使用这些文档进行知识库的检索
原始查询较短，可能无法充分表达用户意图。
通过 Query2Doc 生成一段扩展文档：

示例：
用户查询：“如何提高深度学习模型的训练效率？”
Query2Doc结果：
提高深度学习模型的训练效率可以从以下几个方面入手：
1. 使用更高效的优化算法，如 AdamW 或 LAMB。
2. 采用混合精度训练（Mixed Precision Training），减少显存占用并加速计算。
3. 使用分布式训练技术，如数据并行或模型并行。
4. 对数据进行预处理和增强，减少训练时的冗余计算。
5. 调整学习率调度策略，避免训练过程中的震荡。
====
用户查询：中国有哪些滑雪胜地


Q：Query2Doc感觉Query的结果已经出来了，还需要后续的流程吗
需要，因为RAG是来自于 私有的知识库
LLM进行的Query改写，只是给我们一些示例方向，方便进行 知识库中的chunk匹配

所以最终放到LLM的知识，应该是来自于 我们知识库的

Q：那么多种query优化策略，有什么优缺点，如何选型？

Q：如何进行相互使用？
tool1：query改写
tool2：联网搜索
tool3：问题解读
agent自主选择调用哪个工具

Q：Doc2Query 要怎么用？
imacopilot VS notebooklm

特征工程 => 放到模型中进行训练
数据预处理 => LLM进行推理


知识库
1）对话沉淀
2）点赞 => 点赞本
3）点踩 => 错题本

faiss

Q：知识库的管理都是通过遍历rag 来实现的吗
准确率是怎么出来的？

Q：实际项目中知识库管理使用什么工具？
可以用Agent开发平台，比如 Coze，腾讯智能体开发平台
也有自己开发

Q：知识库和RAG有什么区别？
RAG是知识库的使用过程，包括了 R检索，A增强，G生成

一般企业使用RAG（包括知识库）有两种模式：
1）用现成的大厂的产品，智能体开发平台为例（Coze, 腾讯）
2）自己开发

Q：知识库和向量数据库是什么关系？
向量数据库 是用于筛选知识的，因为它会用 数学工具（cos）进行向量的计算

智能体
知识库

Graph <node, edge>
node 实体（张飞，许昌）
edge 

Q：我比如要检查一份报告，要检查的项，我如果使用知识库来生成检查项一直不全，我是不是可以把这些检查项整体分析后落库呢？
KAG
qwen-agent

Q：Chunk 2 question, 这个部分 所有的 question 存在哪？ 如果我用的是 dify这样的工具，不支持存储 要怎么办？
可以放到知识库

chunk1: 原始txt, 生成的question
chunk2: 原始txt, 生成的question
chunk3: 原始txt, 生成的question


Q：知识库问题查询和知识库向量查询，怎么相互使用的
向量查询 => 帮你筛选chunks 知识的
知识库提问 => Query + 筛选出来的 chunks => LLM来回答

Q：知识库 和 知识图谱 啥区别呢？
知识库 是原始文档
知识图谱 是在原始文档的基础上，建了一个Graph <node, edge>，对原有知识的 笔记整理
